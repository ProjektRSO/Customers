kumuluzee:
  name: customers-service
  env:
    name: dev
  version: 1.0.0
  server:
    base-url: http://localhost:8080
    http:
      port: 8080
  datasources:
    - jndi-name: jdbc/customers
      connection-url: jdbc:postgresql://localhost:5432/customers
      username: kolan51
      password: postgres
  config:
    start-retry-delay-ms: 500
    max-retry-delay-ms: 900000
    etcd:
      hosts: http://192.168.99.100:2379
    consul:
      agent: http://localhost:8500
  rest-properties:
    maintenance-mode: false
  health:
    checks:
      data-source-health-check:
        type: liveness
        jndi-name: jdbc/customers
  metrics:
    web-instrumentation:
      - name: customers-endpoint
        url-pattern: /v1/customers/*
  logs:
    config-file: '<?xml version="1.0" encoding="UTF-8"?>
                        <Configuration name="comments">
                            <Appenders>
                                <Console name="console" target="SYSTEM_OUT">
                                    <PatternLayout pattern="%d %p %marker %m %X %ex %n"/>
                                </Console>
                                <Socket name="logstash" host="7889bb41-f39e-47e8-ba99-7544d8dfb6a5-ls.logit.io"
                                port="12345" protocol="udp">
                                    <JSONLayout complete="false" compact="true" eventEol="true" charset="UTF-8" properties="true"/>
                                </Socket>
                            </Appenders>
                            <Loggers>
                                <!-- Default logger -->
                                <Root level="all">
                                    <AppenderRef ref="console" level="info" />
                                    <AppenderRef ref="logstash" level="trace" />
                                </Root>
                            </Loggers>
                        </Configuration>'
  rest-client:
    registrations:
      - class: customers-processing-api
        url: http://localhost:8082/v1
        read-timeout: 5000
  streaming:
    kafka:
      producer:
        bootstrap-servers: ark-01.srvs.cloudkafka.com:9094
        acks: all
        retries: 0
        batch-size: 16384
        linger-ms: 1
        buffer-memory: 33554432
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.apache.kafka.common.serialization.StringSerializer
        security-protocol: SASL_SSL
        sasl-mechanism: SCRAM-SHA-256
        group-id: newer
        enable-auto-commit: true
        auto-commit-interval-ms: 1000
        auto-offset-reset: earliest
        session-timeout-ms: 30000
        sasl-jaas-config:
app-properties:
  amazon-rekognition:
    access-key:
    secret-key:

# poimenovanje ter dostop do okoljskih spremenljivk

# kumuluzee.name
# kumuluzee.env.name
# kumuluzee.datasources[0].connection-url

# KUMULUZEE_NAME
# KUMULUZEE_ENV_NAME
# KUMULUZEE_DATASOURCES0_CONNECTIONURL

# docker run -d --name rso-workerdb -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=workers -p 5432:5432 postgres:13
# kumuluzee.env.name če bi bilo znotraj
# če datoteka: velike črke in podčrtaj namesto pik KUMULUZEE_ENV_NAME

# docker network create rso2021
# docker run -d --name rso-workerdb -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=workers -p 5432:5432 --network rso2021 postgres:13

# okoljske spremenljivke: v run ukazu z -e IME=vrednost
# jdbc:postgresql://worker-database:5432/workers
# KUMULUZEE_DATASOURCES0_CONNECTIONURL -> sestavljeno iz nivojev te yaml datoteke, 0 tam kjer lahko več
# docker run -d --name workers-MS -p 8080:8080 -e KUMULUZEE_DATASOURCES0_CONNECTIONURL=jdbc:postgresql://rso-workerdb:5432/workers --network rso2021 rso2021.v1

# consul agent -dev, na 8500 portu